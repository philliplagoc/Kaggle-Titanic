{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Titanic Challenge\n",
    "\n",
    "Here is a link to the dataset: https://www.kaggle.com/c/titanic.\n",
    "\n",
    "## Goal\n",
    "Apply machine learning to predict which passengers survived the Titanic sinking. \n",
    "\n",
    "**My goal is to submit a trained model try to go up the leaderboard.** \n",
    "\n",
    "## Overview\n",
    "**training set: train.csv**\n",
    "\n",
    "*Shape*: (891, 12)\n",
    "\n",
    "**testing set: test.csv**\n",
    "\n",
    "*Shape*: (418, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "params = {\n",
    "    'axes.labelsize': 'large',\n",
    "    'xtick.labelsize': 'x-large',\n",
    "    'legend.fontsize': 20,\n",
    "    'figure.dpi': 150,\n",
    "    'figure.figsize': [25,7]\n",
    "}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "First, I will impute the missing values. Then, proceed to pre-processing the data and feature engineering.\n",
    "\n",
    "--- \n",
    "\n",
    "*Survived* is the label I want to predict. 0 means the passenger died, while 1 means they lived.\n",
    "\n",
    "*PassengerId* will not be used in training, and so can be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing the Missing Values - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_missing = train.isnull().sum().sort_values(ascending=False)\n",
    "percent_missing = train.isnull().sum().sort_values(ascending=False) / len(train)\n",
    "missing_train = pd.DataFrame(data=[n_missing, percent_missing])\n",
    "missing_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 19% of the training data is missing *Age*. About 77% is missing *Cabin*, and 2 observations are missing *Embarked*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['Embarked'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute these two observations with the mode of Embarked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Embarked.fillna('C', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing Cabin\n",
    "\n",
    "Since ~77% of the features are missing, one may consider dropping it. But, having no data on *Cabin* can represent the passenger's low socio-economic status, which may be a factor towards their survival. As such, it is better to impute them.\n",
    "\n",
    "The observations missing *Cabin* will be imputed with 'N'.\n",
    "All others will be imputed with the first letter of the *Cabin* variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Cabin.fillna('N', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Cabin.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Cabin = [i[0] for i in train.Cabin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Cabin.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing Age\n",
    "\n",
    "About 20% of the training observations are missing *Age*. To impute these, I will use Linear Regression to predict these missing values. \n",
    "\n",
    "However, this will be done once I engineer more features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing the Missing Values - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_missing = test.isnull().sum().sort_values(ascending=False)\n",
    "percent_missing = test.isnull().sum().sort_values(ascending=False) / len(train)\n",
    "missing_test = pd.DataFrame(data=[n_missing, percent_missing])\n",
    "missing_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "86 of the testing data is missing *Age*. About 36% is missing *Cabin*, and 1 observation is missing *Fare*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test['Fare'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute this observation with the mean of passengers who are 'male', *Pclass* of '3', and *Embarked* from 'S'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_val = test.loc[(test.Sex == 'male') & (test.Pclass == 3) & (test.Embarked == 'S')].Fare.mean()\n",
    "test.Fare.fillna(miss_val, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing Cabin\n",
    "\n",
    "Perform the same imputation done to the training set to be consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Cabin.fillna('N', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Cabin.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Cabin = [i[0] for i in test.Cabin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Cabin.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the training set, there is a *Cabin* with the label 'T'. When this is one-hot encoded, I will drop this column from the training set. Keeping it can cause some complications for training the model. \n",
    "\n",
    "If the model is trained on features that do not exist in the testing set, then the model can overfit the training set, and cannot generalize to new data. The model will have more variance and less bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing Age\n",
    "\n",
    "86 of the testing observations are missing *Age*. To impute these, I will use Linear Regression to predict these missing values. \n",
    "\n",
    "However, this will be done once I engineer more features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Name* - Extract the title of each passenger. A passenger's title can have an effect on whether or not they survived. For instance, those with the title of *Master* may have been given priority to get on a life boat.\n",
    "\n",
    "*SibSp* and *Parch* - Can create new features called *NumFamily*. So, for each passenger, the values of *SibSp* and *Parch* will be added + 1 (the 1 represents the passenger themself). \n",
    "\n",
    "*Ticket* - More analysis needs to be done for this feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting Title from Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(i):\n",
    "    title = i.split(', ')[1].split('.')[0]\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Title'] = train.Name.apply(get_title)\n",
    "test['Title'] = test.Name.apply(get_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_dict = {\n",
    "    'Mr': 'Mr',\n",
    "    'Miss': 'Miss',\n",
    "    'Ms': 'Miss',\n",
    "    'Mrs': 'Mrs',\n",
    "    'Master': 'Master',\n",
    "    'Dr': 'Dr',\n",
    "    'Rev': 'Rev',\n",
    "    'Col': 'Officer',\n",
    "    'Mlle': 'Miss',\n",
    "    'Major': 'Officer',\n",
    "    'the Countess': 'Royal',\n",
    "    'Sir': 'Royal',\n",
    "    'Capt': 'Officer',\n",
    "    'Don': 'Royal',\n",
    "    'Mme': 'Royal',\n",
    "    'Jonkheer': 'Royal',\n",
    "    'Lady': 'Royal',\n",
    "    'Dona': 'Royal'\n",
    "}\n",
    "\n",
    "train.Title = train.Title.map(title_dict)\n",
    "train.drop('Name', axis=1, inplace=True)\n",
    "test.Title = test.Title.map(title_dict)\n",
    "test.drop('Name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Title.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engineering NumFamily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['NumFamily'] = train.SibSp + train.Parch + 1\n",
    "test['NumFamily'] = test.SibSp + test.Parch + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Ticket.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the unique values, there does not seem to be any reasonable way to distinguish/ clear up the data. There are lots of different levels for *Ticket*, and there is no clear way of pre-processing it. \n",
    "\n",
    "One may argue that *Ticket* can represent the socio-economic status of a passenger, which can influence survival. However, this can already be explained by the *Fare*, which is a much more interpretable way of determining the socio-economic status of a passenger.\n",
    "\n",
    "So, I will drop *Ticket* from both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('Ticket', axis=1, inplace=True)\n",
    "test.drop('Ticket', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "\n",
    "*Pclass* - This is an integer, but is really describing is the social class the passenger belongs in (1st, 2nd, 3rd). One-Hot Encode for each social class level.\n",
    "\n",
    "*Cabin*, *Embarked*, *Sex* - One-hot encode this. \n",
    "\n",
    "*Age* - Use Linear Regression to determine the missing *Age* values.\n",
    "\n",
    "*PassengerId* - Drop this, since we won't need this in training. \n",
    "\n",
    "---\n",
    "\n",
    "After imputing *Age*, drop *Cabin_T* from the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('PassengerId', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns=['Title','Pclass','Embarked', 'Sex', 'Cabin'])\n",
    "test = pd.get_dummies(test, columns=['Title','Pclass','Embarked', 'Sex', 'Cabin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('Cabin_T', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing Age Via Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_age(df):\n",
    "    temp_test = df.loc[df.Age.isnull()]\n",
    "    temp_train = df.loc[df.Age.notna()]\n",
    "\n",
    "    temp_train_X = temp_train.loc[:, 'SibSp':]\n",
    "    temp_test_X = temp_test.loc[: , 'SibSp':]\n",
    "    temp_train_y = temp_train.Age\n",
    "    temp_test_y = temp_test.Age\n",
    "\n",
    "    logreg = LinearRegression().fit(temp_train_X, temp_train_y)\n",
    "    preds = logreg.predict(temp_test_X)\n",
    "\n",
    "    df.loc[df.Age.isnull(), 'Age'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_age(train)\n",
    "impute_age(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "**After Feature Extraction and Pre-Processing...**\n",
    "\n",
    "train - Shape: (891,31)\n",
    "\n",
    "test - Shape: (418, 30)\n",
    "\n",
    "### Heat-map of the correlation of Top 10 Features on Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_mat = train.corr(method='pearson')\n",
    "corr_cols = correlation_mat.nlargest(10, 'Survived')['Survived'].index\n",
    "correlation_mat = np.corrcoef(train[corr_cols].values.transpose())\n",
    "f, ax = plt.subplots(figsize=(10,8))\n",
    "sns.set(font_scale=1.25)\n",
    "sns.heatmap(correlation_mat, square=True, annot=True, \n",
    "            yticklabels=corr_cols.values, xticklabels=corr_cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being a female was correlated relatively strongly with survival. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Survival on Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_females_survived = train[(train['Sex_female'] == 1) & (train['Survived'] == 1)].Sex_female.sum()\n",
    "\n",
    "n_males_survived = train[(train['Sex_male'] == 1) & (train['Survived'] == 1)].Sex_male.sum()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10,8))\n",
    "sns.barplot(x=['Males', 'Females'], y=[n_males_survived, n_females_survived]) \n",
    "plt.title('Gender vs. Survival')\n",
    "plt.ylabel('No. Survived')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total_females = train[(train['Sex_female'] == 1)].Sex_female.sum()\n",
    "n_total_males = train[(train['Sex_male'] == 1)].Sex_male.sum()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10,8))\n",
    "sns.barplot(x=['Males', 'Females'], y=[n_total_males, n_total_females]) \n",
    "plt.title('Gender vs. Amount that Boarded')\n",
    "plt.ylabel('No. Boarded')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percent of Males that Survived: ', n_males_survived / n_total_males)\n",
    "print('Percent of Females that Survived: ', n_females_survived / n_total_females)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Survival on Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_firstclass_survived = train[(train['Pclass_1'] == 1) & (train['Survived'] == 1)].Pclass_1.sum()\n",
    "n_secondclass_survived = train[(train['Pclass_2'] == 1) & (train['Survived'] == 1)].Pclass_2.sum()\n",
    "n_thirdclass_survived = train[(train['Pclass_3'] == 1) & (train['Survived'] == 1)].Pclass_3.sum()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10,8))\n",
    "sns.barplot(x=['First Class', 'Second Class', 'Third Class'], \n",
    "            y=[n_firstclass_survived, n_secondclass_survived, n_thirdclass_survived]) \n",
    "plt.title('Passenger Class vs. Survival')\n",
    "plt.ylabel('No. Survived')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_firstclass_total = train[(train['Pclass_1'] == 1)].Pclass_1.sum()\n",
    "n_secondclass_total = train[(train['Pclass_2'] == 1)].Pclass_2.sum()\n",
    "n_thirdclass_total = train[(train['Pclass_3'] == 1)].Pclass_3.sum()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10,8))\n",
    "sns.barplot(x=['First Class', 'Second Class', 'Third Class'], \n",
    "            y=[n_firstclass_total, n_secondclass_total, n_thirdclass_total]) \n",
    "plt.title('Passenger Class vs. Total that Boarded')\n",
    "plt.ylabel('No. Boarded')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percent of First Class that Survived: ', n_firstclass_survived / n_firstclass_total)\n",
    "print('Percent of Second Class that Survived: ', n_secondclass_survived / n_secondclass_total)\n",
    "print('Percent of Third Class that Survived: ', n_thirdclass_survived / n_thirdclass_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "- **Logistic Regression**\n",
    "\n",
    "Hyper-parameters: \n",
    "\n",
    "C = [0.05, 0.01, 0.5, 0.1, 1, 1.5, 2]\n",
    "\n",
    "penalty = ['l1', 'l2']                \n",
    "\n",
    "- **Support Vector Machine**\n",
    "\n",
    "Hyper-parameters: \n",
    "\n",
    "C = [0.05, 0.01, 0.5, 0.1, 1, 1.5, 2]\n",
    "\n",
    "kernel = ['linear', 'poly', 'rbf']\n",
    "\n",
    "degree = [2, 3]\n",
    "\n",
    "- **K-Nearest Neighbors**\n",
    "\n",
    "Hyper-parameters: \n",
    "\n",
    "n_neighbors = [2...10]\n",
    "\n",
    "- **Decision Tree Classifier**\n",
    "\n",
    "Hyper-parameters:\n",
    "\n",
    "criterion = ['entropy']\n",
    "\n",
    "max_depth = [2...10]\n",
    "\n",
    "min_samples_split = [2...10]\n",
    "\n",
    "After fitting the above, I will then use VotingClassifier, which is used for ensemble learning.\n",
    "\n",
    "Error Metric: Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.iloc[:, 1:]\n",
    "y = train.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_list = [0.05, 0.01, 0.5, 0.1, 1, 1.5, 2]\n",
    "penalty_list = ['l1', 'l2']\n",
    "logreg_params = {'C': C_list, 'penalty': penalty_list}\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg_grid = GridSearchCV(logreg, logreg_params, cv=5, scoring='accuracy')\n",
    "logreg_grid.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_star = logreg_grid.best_estimator_.fit(X_train_val, y_train_val)\n",
    "acc = accuracy_score(logreg_star.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Logistic Regression Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors_list=np.arange(1, 11, 1)\n",
    "knn_params = {'n_neighbors': n_neighbors_list}\n",
    "\n",
    "knn_grid = KNeighborsClassifier()\n",
    "\n",
    "knn_grid = GridSearchCV(knn_grid, knn_params, cv=5, scoring='accuracy')\n",
    "knn_grid.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_star = knn_grid.best_estimator_.fit(X_train_val, y_train_val)\n",
    "acc = accuracy_score(knn_star.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('K-Nearest Neighbors Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_list = ['gini', 'entropy']\n",
    "max_depth_list = np.arange(2, 11, 1)\n",
    "min_samples_split_list = np.arange(2, 11, 1)\n",
    "\n",
    "dt_params = {'criterion': criterion_list, 'max_depth': max_depth_list, \n",
    "             'min_samples_split': min_samples_split_list}\n",
    "\n",
    "dt_grid = DecisionTreeClassifier()\n",
    "dt_grid = GridSearchCV(dt_grid, dt_params, cv=5, scoring='accuracy')\n",
    "\n",
    "dt_grid.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_star = dt_grid.best_estimator_.fit(X_train_val, y_train_val)\n",
    "acc = accuracy_score(dt_star.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Decision Tree Classifier Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_list = ['linear', 'poly', 'rbf']\n",
    "degree_list = [2, 3]\n",
    "gamma_list = [10e-3, 10e-2, 1, 2]\n",
    "svc_params = {'C': C_list, 'kernel': kernel_list, 'degree': degree_list, 'gamma': gamma_list}\n",
    "\n",
    "svc_grid = SVC()\n",
    "\n",
    "svc_grid = GridSearchCV(svc_grid, svc_params, cv=5, scoring='accuracy')\n",
    "svc_grid.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_star = svc_grid.best_estimator_.fit(X_train_val, y_train_val)\n",
    "acc = accuracy_score(svc_star.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SVM Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('logreg_grid', logreg_grid),\n",
    "    ('svc_grid', svc_grid),\n",
    "    ('knn_grid', knn_grid),\n",
    "    ('dt_grid', dt_grid)\n",
    "], voting='soft').fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = voting_clf.predict(X_test)\n",
    "acc = accuracy_score(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Voting Classifier Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengerId = test.PassengerId\n",
    "test.drop('PassengerId', axis=1, inplace=True)\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test.PassengerId\n",
    "    'Survived': voting_clf.predict(test)\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
